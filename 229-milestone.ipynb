{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.impute import SimpleImputer\n\n# Deep Learning\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ee6824cf41c4fd03be113d54e6975cf3574c06f"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()\nprint(f'Market Data: {market_train_df.shape[0]} training examples, {market_train_df.shape[1]} cols.')\nprint(f'News Data: {news_train_df.shape[0]} training examples, {news_train_df.shape[1]} cols.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d65cd904382baa0de1fcbb8db1f4024a95b9200"},"cell_type":"code","source":"market_train_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90d7f52416bd4bdace0f68717c982e9554164c59"},"cell_type":"code","source":"news_train_df[[\"headline\",\"provider\",\"subjects\",\"bodySize\",\"sentenceCount\",\"assetCodes\",\"sentimentClass\",\"sentimentNegative\",\"sentimentNeutral\", \"sentimentPositive\",\"sentimentWordCount\"]][1:4][::-1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e784d89a6731a06bc75b5c0ded3730ec6d43701"},"cell_type":"markdown","source":"## Modelling"},{"metadata":{"trusted":true,"_uuid":"12799708ae2b1c12d03ac121931446830dc32b17","scrolled":true},"cell_type":"code","source":"def prep_market_df(market_df):\n    market_df['time'] = market_df.time.dt.date\n    #market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] / market_df['volume']\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df['volume_to_mean'] = market_df['volume'] / market_df['volume'].mean()\n    return market_df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45259839f059326c75d073977d4fe69c16d73cf0"},"cell_type":"code","source":"def prep_news_df(news_df):\n    news_df['sentence_word_count'] =  news_df['wordCount'] / news_train_df['sentenceCount']\n    news_df['time'] = news_df.time.dt.hour\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['headlineLen'] = news_df['headline'].apply(lambda x: len(x))\n    news_df['assetCodesLen'] = news_df['assetCodes'].apply(lambda x: len(x))\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['asset_sentence_mean'] = news_df.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    lbl = {k: v for v, k in enumerate(news_df['headlineTag'].unique())}\n    news_df['headlineTagT'] = news_df['headlineTag'].map(lbl)\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n    return news_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d642be9ed92bb181d9c8de494207d6cc8e2ae3ce"},"cell_type":"code","source":"def merge_news_and_market_data(market_df,news_df):\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['time', 'assetCode'], right_on=['firstCreated', 'assetCodes'])\n    lbl = {k: v for v, k in enumerate(market_df['assetCode'].unique())}\n    market_df['assetCodeT'] = market_df['assetCode'].map(lbl)\n    market_df = market_df.dropna(axis=0)\n    return market_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57973e95286b66b3f475859c110d12db37873609","_kg_hide-input":true},"cell_type":"code","source":"# code mostly takes from this kernel: https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-xgb\ndef data_prep(market_df,news_df):\n    market_df = prep_market_df(market_df)\n    news_df = prep_news_df(news_df)\n    merged_df = merge_news_and_market_data(market_df,news_df)\n    return merged_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b73fbbba614fe6a617d847a228e88223a3d2f3f0"},"cell_type":"code","source":"def get_feature_cols(data_df):\n    return [c for c in data_df.columns if c not in \n     ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'assetCodeT',\n    'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider',\n    'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57a46e8137a6a83c07c2eb9851b5d520822e3596"},"cell_type":"code","source":"def scale_data(X):\n    mins = np.min(X, axis=0)\n    maxs = np.max(X, axis=0)\n    rng = maxs - mins\n    return 1 - ((maxs - X) / rng),maxs,mins,rng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea26378d4d940955a5d84b43d0d85506780ea6b7","scrolled":true},"cell_type":"code","source":"market_train = data_prep(market_train_df, news_train_df)\nclass_labels = market_train.returnsOpenNextMktres10 >= 0\nfcol = get_feature_cols(market_train)\nX = market_train[fcol].values\nclass_labels = class_labels.values\nr = market_train.returnsOpenNextMktres10.values\n\nX,maxs,mins,rng = scale_data(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf982074f53a1e1fcb5bac688f3d8717c49e4f3a"},"cell_type":"code","source":"print(fcol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6bd3c043498d67c5e7d1e71fc205a062aacfcf5"},"cell_type":"code","source":"print(r[:6])\nprint(class_labels[:6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9695eface6eee79f079e168d97ced1835e868436"},"cell_type":"code","source":"X_train, X_test, class_labels_train, class_labels_test, r_train, r_test = model_selection.train_test_split(X, class_labels, r, test_size=0.1, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfcdc4af4815ae8d52a453d930b1b03da903dbde"},"cell_type":"code","source":"def build_lgb_model(X_train, X_test, class_labels_train, class_labels_test):\n    params = {'learning_rate': 0.05, 'max_depth': 12, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\n    model = lgb.train(params, train_set=lgb.Dataset(X_train, label=class_labels_train), num_boost_round=2000,\n                      valid_sets=[lgb.Dataset(X_train, label=class_labels_train), lgb.Dataset(X_test, label=class_labels_test)],\n                      verbose_eval=100, early_stopping_rounds=100)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"439e90ede689ee697a98912980bc98505f645297"},"cell_type":"code","source":"def build_logreg_model(X_train, X_test, class_labels_train, class_labels_test, impute=True):\n    \n    # Handle NaN/missing vals by imputing if impute set to True\n    if impute:\n        my_imputer = SimpleImputer()\n        X_train = my_imputer.fit_transform(X_train)\n        X_test = my_imputer.fit_transform(X_test)\n    \n    clf = LogisticRegression(random_state=0, solver='sag',multi_class='ovr',verbose=1).fit(X_train, class_labels_train)\n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f0987c766382dc196cc71699636f48338a5d222"},"cell_type":"code","source":"def build_sgd_model(X_train, X_test, class_labels_train, class_labels_test, impute=True):\n    \n    # Handle NaN/missing vals by imputing if impute set to True\n    if impute:\n        my_imputer = SimpleImputer()\n        X_train = my_imputer.fit_transform(X_train)\n        X_test = my_imputer.fit_transform(X_test)\n    \n    clf = SGDClassifier(loss='log', penalty='l2', alpha=0.05,max_iter=1000, verbose=1).fit(X_train, class_labels_train)\n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32385837c368d0c6008cfaa7fe9c95526d1817d1"},"cell_type":"code","source":"def create_baseline():\n    model = Sequential()\n    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1,kernel_initializer='normal', activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02663cb5b53f0470ae86e1ec7e14c99080f3ebc7"},"cell_type":"code","source":"def create_two_layer_baseline():\n    model = Sequential()\n    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6593d657b19df68215652d74b8ea09e02c5cd08"},"cell_type":"code","source":"def create_three_layer_NN():\n    model = Sequential()\n    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n    #model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n    #model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n    #model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"405496691b85ef6e69a65e8bec9de76db65fa1eb"},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\ndef build_shallow_NN_model(X_train, X_test, class_labels_train, class_labels_test, impute=True, num_hidd_layers=1):\n    \n    if impute:\n        my_imputer = SimpleImputer()\n        print(X_train.shape)\n        X_train = my_imputer.fit_transform(X_train)\n        print(X_train.shape)\n        #X_test = my_imputer.fit_transform(X_test)\n        \n    shallow_net_model = None\n        \n    if num_hidd_layers == 1:\n        shallow_net_model = create_baseline()\n    elif num_hidd_layers == 2:\n        shallow_net_model = create_two_layer_baseline()\n    elif num_hidd_layers == 3:\n        shallow_net_model = create_three_layer_NN()\n    #shallow_net_model = create_baseline()#X_train.shape[1]\n    max_epochs = 10\n    class_int_labels_train = (class_labels_train == True).astype(int)\n    assert(len(X_train == len(class_int_labels_train)))\n    #early_stop = EarlyStopping(patience=5,verbose=True)\n    h = shallow_net_model.fit(X_train, class_int_labels_train, batch_size=32,epochs=max_epochs, verbose=1)#,callbacks=[early_stop]\n    return shallow_net_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"189928d822d24e581a0cffa10719b5ffa419809f"},"cell_type":"code","source":"def test_NN(model, X_test,Y_test, impute=True):\n    print(X_test.shape,Y_test.shape)\n    merged = np.concatenate((X_test, Y_test.reshape((Y_test.shape[0], 1))), axis=1)\n    print(merged.shape)\n    if impute:\n        my_imputer = SimpleImputer()\n        merged = my_imputer.fit_transform(merged)\n        print(merged.shape)\n        X_test = merged[:,:-1]\n        Y_test = merged[:,-1]\n        print(X_test.shape, Y_test.shape, Y_test[:4])\n        #X_test = my_imputer.fit_transform(X_train)\n        #Y_test = my_imputer.fit_transform(Y_test)\n    eval_results = model.evaluate(X_test, Y_test,verbose=1)\n    e = model.predict(X_test).squeeze()\n    print(e)\n    print(\"\\nLoss, accuracy on test data: \")\n    print(\"%0.4f %0.2f%%\" % (eval_results[0], eval_results[1]*100))\n    return e\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bad4326e64262374ce4d3ba8839e5b73efa7b88"},"cell_type":"code","source":"def test_non_NN_model(model, X_test,Y_test, impute=True,logreg=False):\n    merged = np.concatenate((X_test, Y_test.reshape((Y_test.shape[0], 1))), axis=1)\n    if impute:\n        my_imputer = SimpleImputer()\n        merged = my_imputer.fit_transform(merged)\n        print(merged.shape)\n        X_test = merged[:,:-1]\n        Y_test = merged[:,-1]\n        print(X_test.shape, Y_test.shape, Y_test[:4])\n        #X_test = my_imputer.fit_transform(X_train)\n        #Y_test = my_imputer.fit_transform(Y_test)\n    eval_results = None\n    if logreg:\n        eval_results = model.predict_proba(X_test)[:,1]\n    else:\n        eval_results = model.predict(X_test)#, Y_test,verbose=1)\n    print(max(eval_results))\n    thresholded = [1  if ex >= 0.5 else 0 for ex in eval_results]\n    acc = np.mean(thresholded == Y_test)\n    print(\"\\nAccuracy on test data: \")\n    print(\"%0.2f%%\" % (acc*100))\n    print(eval_results)\n    return eval_results\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5190fffb5a49859564ac76fcd5cbace09fce50da"},"cell_type":"code","source":"#lgb_model = build_lgb_model(X_train, X_test, class_labels_train, class_labels_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"809e93b3dfc4a5bc54fb03444dd28cb138e9c96a","scrolled":true},"cell_type":"code","source":"logreg_model = build_logreg_model(X_train, X_test, class_labels_train, class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77fac54426ba9f774366ec20e999adc75afbc4bd"},"cell_type":"code","source":"#sgd_model = build_sgd_model(X_train, X_test, class_labels_train, class_labels_test, impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4b1526393a9619633bad20ea31039316d8f1ff0"},"cell_type":"code","source":"hidden_layers = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e2bbe24f5e699903205afbae7afad9bbf377a79","scrolled":true},"cell_type":"code","source":"batchnorm_model = build_shallow_NN_model(X_train, X_test, class_labels_train, class_labels_test, impute=True,num_hidd_layers=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6c647de169118a5babfc8f78641177346a02dbed"},"cell_type":"code","source":"shallow_net_model = build_shallow_NN_model(X_train, X_test, class_labels_train, class_labels_test, impute=True,num_hidd_layers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2690a24b0e8d0d66cf3ca88a34b7fdc7cd951b36"},"cell_type":"code","source":"#test_non_NN_model(lgb_model,X_test,class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f6f4c8d3ca8b309b543b979c24142bd6100dd04","scrolled":false},"cell_type":"code","source":"#test_NN(dropout_model,X_test,class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4046662d87cd9f52e4d9ab75c778f097c6e510f7"},"cell_type":"code","source":"#test_NN(shallow_net_model,X_test,class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6adafef2bc16c1fd91e8aa368d9a57a2dd0878af"},"cell_type":"code","source":"def ensemble(predictions, method=\"mean\"):\n    num_models = len(predictions)\n    results = None\n    weights = [0.7,0.1,0.1,0.1]\n    if method==\"median\":\n        results = []\n        for ex in range(len(predictions[0])):\n            curr_preds = [predictions[model_idx][ex] for model_idx in range(num_models)]\n            pred = np.mean(curr_preds)\n            results.append(pred)\n    elif method == \"weighted\":\n        results = []\n        for ex in range(len(predictions[0])):\n            pred = np.sum([predictions[model_idx][ex]*weights[model_idx] for model_idx in range(num_models)])\n            #print(pred)\n            results.append(pred)\n    else:\n        summed = np.sum(predictions,axis=0)\n        print(len(summed))\n        results = summed / float(num_models)\n    return results\n    #summed = np.sum(predictions,axis=0)\n    #print(len(summed))\n    #return summed / float(num_models)\n    #return np.mean(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a60954c8e799ec1bf1cfdfcc821efbc13d33dfb5"},"cell_type":"code","source":"#lgb_results = test_non_NN_model(lgb_model,X_test,class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a070e2d6d927f58d8064e66523306f56f1aad4f0"},"cell_type":"code","source":"logreg_results = test_non_NN_model(logreg_model,X_test,class_labels_test,impute=True,logreg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82548b86ec7e7339fda003d7fb6e31f3c11ff8b4"},"cell_type":"code","source":"shallow_results = test_NN(shallow_net_model,X_test,class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce9b1306d12297291a841507a664c7212aa78d52"},"cell_type":"code","source":"batchnorm_results = test_NN(batchnorm_model,X_test,class_labels_test,impute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"264aecc2261ed169f3a7ad3e344fcd9ea2365abc"},"cell_type":"code","source":"predictions = [logreg_results,shallow_results,batchnorm_results]\n#for i in range(4):\n#    print(predictions[i][0])\n#print(predictions[0])\nensemble_predictions = ensemble(predictions,method=\"mean\")\nprint(ensemble_predictions)\n#x = 0.5397711618234922+0.5166342344290076+0.53550625+0.50618184\n#print(x/4.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9398cc67b3bd30534e00b4c0c7f063c076403650"},"cell_type":"code","source":"def test_ensemble(predictions,Y_test):\n    thresholded = np.array([1  if ex >= 0.5 else 0 for ex in predictions])\n    print(thresholded[:10],Y_test[0:10])\n    Y_test = np.array([int(x) for x in Y_test])\n    #acc = np.mean(thresholded == Y_test)\n    same = 0.0\n    for i in range(len(predictions)):\n        if thresholded[i] == Y_test[i]:\n            same += 1\n    acc = same/float(len(predictions))\n    print(\"%0.2f%%\" % (acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e421190da52da3cdd31c0fb75fbeb18703532a9d"},"cell_type":"code","source":"test_ensemble(ensemble_predictions,class_labels_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d36435f7a4b750c418c6a9ea0a447c26abb2da4"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7b548b08eb281b4a341d235cbeea8b7e1201a36","scrolled":true},"cell_type":"code","source":"n_days = 0\nimpute = True\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n        \n    market_obs_df = data_prep(market_obs_df, news_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    \n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    #lp = shallow_net_model.predict(X_live).squeeze()\n    #lp_predictions = dropout_model.predict(X_live).squeeze()\n    #lgb_prediction = lgb_model.predict(X_live)\n    logreg_prediction = logreg_model.predict_proba(X_live)[:,1]\n    shallow_net_model_prediction = shallow_net_model.predict(X_live).squeeze()\n    batchnorm_model_prediction = batchnorm_model.predict(X_live).squeeze()\n    #print(logreg_prediction,shallow_net_model_prediction,batchnorm_model_prediction)\n    lp = np.mean([logreg_prediction,shallow_net_model_prediction,batchnorm_model_prediction])\n    #lp = batchnorm_model_prediction\n    confidence = 2 * lp -1\n    #print(confidence)\n\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12a65ba92ed0f1185a8c4b30c0f8142da4ec8418"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}